{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78bf69b5-b237-4561-8687-b775306cbbec",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415a34d4-2b82-4551-b19a-fe35f06ae656",
   "metadata": {},
   "source": [
    "#### Update SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29fd712b-6149-4a0b-a610-f60f11fa1baf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U sagemaker --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf58094-779d-4c6d-8744-b8761008c280",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cf3892c9-1dcf-40f9-a434-82b75d48b529",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "import pickle\n",
    "import sagemaker as sm\n",
    "\n",
    "from sagemaker import image_uris\n",
    "from sagemaker import model_uris\n",
    "from sagemaker import script_uris\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.utils import name_from_base\n",
    "\n",
    "from sagemaker.jumpstart.notebook_utils import list_jumpstart_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d2f8c7-b992-4f54-ba7c-586a19582056",
   "metadata": {},
   "source": [
    "### SageMaker Configuration Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dac40b85-edf2-4c98-8a64-cba9372a40d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "role               = sm.get_execution_role()\n",
    "sagemaker_session  = sm.session.Session()\n",
    "region             = sagemaker_session._region_name\n",
    "sagemaker_metadata = json.load(open('/opt/ml/metadata/resource-metadata.json', 'r'))\n",
    "domain_id          = sagemaker_metadata['DomainId']\n",
    "resource_name      = sagemaker_metadata['ResourceName']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6e8a58-4fdb-4a11-bfcf-88b90f380d42",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d37eda5-8c47-4942-bd71-c6667f8e56f3",
   "metadata": {},
   "source": [
    "## Select Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0724ec9a-9389-4d2d-9b6a-72758447bf08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available text2text Models:\n",
      "--------------------------------\n",
      "huggingface-text2text-bart4csc-base-chinese\n",
      "huggingface-text2text-bigscience-t0pp\n",
      "huggingface-text2text-bigscience-t0pp-bnb-int8\n",
      "huggingface-text2text-bigscience-t0pp-fp16\n",
      "huggingface-text2text-flan-t5-base\n",
      "huggingface-text2text-flan-t5-base-samsum\n",
      "huggingface-text2text-flan-t5-large\n",
      "huggingface-text2text-flan-t5-small\n",
      "huggingface-text2text-flan-t5-xl\n",
      "huggingface-text2text-flan-t5-xxl\n",
      "huggingface-text2text-flan-t5-xxl-bnb-int8\n",
      "huggingface-text2text-flan-t5-xxl-fp16\n",
      "huggingface-text2text-flan-ul2-bf16\n",
      "huggingface-text2text-pegasus-paraphrase\n",
      "huggingface-text2text-qcpg-sentences\n",
      "huggingface-text2text-t5-one-line-summary\n"
     ]
    }
   ],
   "source": [
    "filter_value = \"task == text2text\"\n",
    "text_generation_models = list_jumpstart_models(filter=filter_value)\n",
    "print('Available text2text Models:\\n--------------------------------')\n",
    "_ = [print(m) for m in text_generation_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df38c2e6-5d99-406a-b3a9-3c4162d1a44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model that will be deployed is: huggingface-text2text-flan-t5-small\n"
     ]
    }
   ],
   "source": [
    "model_id = text_generation_models[7]\n",
    "model_version = '*'\n",
    "print(f'The model that will be deployed is: {model_id}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1306720c-2ee4-48fb-802e-2064b0d44f01",
   "metadata": {},
   "source": [
    "## Deploy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61a7586a-4c4e-486d-bfd0-998a7a8f69f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint: LLM-in-a-box-huggingface-text2text-flan-2023-05-03-18-12-21-023\n"
     ]
    }
   ],
   "source": [
    "endpoint_name = name_from_base(f\"LLM-in-a-box-{model_id}\")\n",
    "print(f'Endpoint: {endpoint_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b19954e-bdb2-4859-aa9b-b5f52ede865d",
   "metadata": {},
   "source": [
    "### Collect the containers required to deploy the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e6a4ca61-a4c0-4732-bd15-65eaa48cfc77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instance_type = \"ml.p2.xlarge\"\n",
    "\n",
    "image_uri = image_uris.retrieve(\n",
    "    region=None,\n",
    "    framework=None,\n",
    "    image_scope=\"inference\",\n",
    "    model_id=model_id,\n",
    "    model_version=model_version,\n",
    "    instance_type=instance_type,\n",
    ")\n",
    "\n",
    "source_dir = script_uris.retrieve(\n",
    "    model_id=model_id,\n",
    "    model_version=model_version,\n",
    "    script_scope=\"inference\"\n",
    ")\n",
    "\n",
    "model_data = model_uris.retrieve(\n",
    "    model_id=model_id,\n",
    "    model_version=model_version,\n",
    "    model_scope=\"inference\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e625234b-0401-4e03-8f5a-fbce67884f7a",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6257ecb7-910a-4407-b357-2d38cf354290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------!"
     ]
    }
   ],
   "source": [
    "model = Model(\n",
    "    image_uri=image_uri,\n",
    "    source_dir=source_dir,\n",
    "    model_data=model_data,\n",
    "    entry_point=\"inference.py\",  # entry point file in source_dir and present in deploy_source_uri\n",
    "    role=role,\n",
    "    predictor_cls=Predictor,\n",
    "    name=endpoint_name,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "\n",
    "# deploy the Model. Note that we need to pass Predictor class when we deploy model through Model class,\n",
    "# for being able to run inference through the sagemaker API.\n",
    "model_predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    predictor_cls=Predictor,\n",
    "    endpoint_name=endpoint_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66f1410-f994-499f-a886-2adef921cef7",
   "metadata": {},
   "source": [
    "#### Test that the model is correctly deployed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "796ef379-3675-4c7b-84dd-8fff204108f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the first time the world cup has been held in the world.\n"
     ]
    }
   ],
   "source": [
    "sagemaker = boto3.client('sagemaker-runtime', region_name=region)\n",
    "input_question = 'The World Cup is '\n",
    "\n",
    "response = sagemaker.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType=\"application/x-text\",\n",
    "    Body=input_question.encode('utf-8')\n",
    ")\n",
    "output_answer = json.loads(response['Body'].read().decode('utf-8'))[\"generated_text\"]\n",
    "print(output_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0dcc03-e13f-4cbe-93cb-605b39c20e3f",
   "metadata": {},
   "source": [
    "### Export any variables needed for the application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2b14d430-1f59-492c-bfb7-3aafa1a9924a",
   "metadata": {},
   "outputs": [],
   "source": [
    "application_metadata = {'endpoint_name':endpoint_name, 'region':region}\n",
    "pickle.dump(application_metadata, open('application_metadata.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70f1c50-0418-4875-bcfe-633b37bcce86",
   "metadata": {},
   "source": [
    "# Create Question-Answer Interface\n",
    "This cell creates the UI that allows users to query a model with a question and displays the resulting generated text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "65b90d78-376d-46ee-892e-997444bb57a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "import os\n",
    "import json\n",
    "import boto3\n",
    "import pickle\n",
    "import streamlit as st\n",
    "from collections import deque\n",
    "from datetime import datetime\n",
    "\n",
    "# \n",
    "application_metadata = pickle.load(open('application_metadata.pkl','rb'))\n",
    "sagemaker = boto3.client('sagemaker-runtime', region_name=application_metadata['region'])\n",
    "endpoint_name = application_metadata['endpoint_name']\n",
    "\n",
    "# \n",
    "st.title('Amazon SageMaker + Generative AI (QnA)')\n",
    "st.write('This demo uses a simple UI to provide access to SageMaker JumpStart and Foundation Models. Type in a question you are itersted in learning more about abd see what is returned. The most recent questions are displayed below.')\n",
    "\n",
    "# \n",
    "input_question = st.text_input('**Please ask a question:**', '')\n",
    "\n",
    "# \n",
    "previous_questions_filename = 'previous_questions.txt'\n",
    "if os.path.isfile(previous_questions_filename):\n",
    "    with open(previous_questions_filename, 'r') as fp:\n",
    "        previous_questions = deque([line.strip() for line in fp.readlines()], maxlen=10)\n",
    "else:\n",
    "    previous_questions = deque(maxlen=10)\n",
    "\n",
    "# \n",
    "if st.button('Send Question') and len(input_question) > 3:\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
    "    payload = {\n",
    "        \"text_inputs\": input_question,\n",
    "        \"max_length\": 150,\n",
    "        \"max_time\": 50,\n",
    "        \"num_return_sequences\": 1,\n",
    "        \"top_k\": 50,\n",
    "        \"top_p\": 0.95,\n",
    "        \"do_sample\": True,\n",
    "    }\n",
    "    \n",
    "    if True:\n",
    "        response = sagemaker.invoke_endpoint(\n",
    "            EndpointName=endpoint_name,\n",
    "            ContentType='application/json',\n",
    "            Body=json.dumps(payload).encode('utf-8')\n",
    "        )\n",
    "        output_answer = json.loads(response['Body'].read().decode('utf-8'))[\"generated_texts\"][0]\n",
    "    else:\n",
    "        output_answer = 'I am not currently connected to an endpoint'\n",
    "    st.text_area('Response:', output_answer)\n",
    "    \n",
    "    # \n",
    "    previous_questions.append('**' + timestamp + ':** ' + input_question)\n",
    "    with open('previous_questions.txt', 'w') as fp:\n",
    "        fp.write('\\n'.join(previous_questions))\n",
    "\n",
    "# \n",
    "st.subheader('Recent Questions:')\n",
    "_ = [st.write(f'{q}') for i,q in enumerate(reversed(previous_questions))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28f8983-425c-4600-bda2-ee9db3aa35c6",
   "metadata": {},
   "source": [
    "# Start App"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352f01d9-2999-4605-94dd-f3a01793ed7a",
   "metadata": {},
   "source": [
    "### Run Streamlit\n",
    "To run the application:\n",
    "1. Select File > New > Terminal\n",
    "2. In the terminal, use the command: `streamlit run app.py --server.runOnSave true`\n",
    "3. If this is successful, you will be able to interact with the app by using the web address below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fce21e-bd5a-423c-800b-ebef4f6b0977",
   "metadata": {},
   "source": [
    "#### Display Link to Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "379d0c40-e193-41bc-a349-c41272e684ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://d-qxdwe39zkab0.studio.us-east-1.sagemaker.aws/jupyter/default/proxy/8501/\n"
     ]
    }
   ],
   "source": [
    "print(f'http://{domain_id}.studio.us-east-1.sagemaker.aws/jupyter/default/proxy/8501/')"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
