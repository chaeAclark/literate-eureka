{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c2c2244-ef22-4904-9fd7-e8eb32d68a87",
   "metadata": {},
   "source": [
    "# LLMs in a Box\n",
    "1. Create a SageMaker Studio Domain if you don't have one\n",
    "2. Open SageMaker Studio under the user you plan to launch this applicatio\n",
    "3. Either upload this notebook, or clone the repository: [repo](https://github.com/chaeAclark/literate-eureka.git)\n",
    "4. Open the notebook `LLM in a box.ipynb`\n",
    "5. You can run the entire notebook by clicking Run > Run All Cells\n",
    "6. Alternatively, you can run the cells individually\n",
    "7. NOTE: To display the image of an uploaded document, you must have poppler utils installed\n",
    "    1. `sudo yum install poppler-utils`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e380410-047f-45e7-a78d-388b3c250826",
   "metadata": {},
   "source": [
    "### Terminal Installation\n",
    "You need to ensure you have installed all needed packages in the terminal you are using.\n",
    "1. boto3\n",
    "2. streamlit\n",
    "3. pdf2image\n",
    "4. ai21[SM]\n",
    "5. Pillow\n",
    "6. pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e98ee6-402f-4dc5-ac7b-28d7958f4cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile requirements.txt\n",
    "boto3\n",
    "streamlit\n",
    "pdf2image\n",
    "ai21[SM]\n",
    "Pillow\n",
    "pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d488a4-dc68-4d1c-8efb-56e313cc86fb",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472f1b1b-cef6-49f8-9546-9d421f80a9ba",
   "metadata": {},
   "source": [
    "#### Update SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f041d93d-9f72-4b1a-9efb-1efabc37da23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U sagemaker --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc66d22-7dee-4ef7-ada9-b25900fa6f45",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8b7491-37ea-4ab3-a657-044d9849a122",
   "metadata": {},
   "source": [
    "### General Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b93011-dd32-4d0d-a072-dec8697b286b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc48ac3-98de-4178-b99a-be9bd650212f",
   "metadata": {},
   "source": [
    "### SageMaker Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cce0167c-5ac4-4ad9-a64b-e3c6c928b05c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import boto3\n",
    "import pickle\n",
    "import sagemaker as sm\n",
    "\n",
    "from sagemaker import image_uris\n",
    "from sagemaker import model_uris\n",
    "from sagemaker import script_uris\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.utils import name_from_base\n",
    "\n",
    "from sagemaker.jumpstart.notebook_utils import list_jumpstart_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22fbfba-019e-4c43-a2b5-c8629c830f7b",
   "metadata": {},
   "source": [
    "### Deploy and Directory Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "801fdd4f-f3c0-4605-8b50-f2ca09366e64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_sagemaker_session(local_download_dir) -> sm.Session:\n",
    "    \"\"\"\n",
    "    # Create a SageMaker Session\n",
    "    # This function is used to create a SageMaker Session object.\n",
    "    # The SageMaker Session object is used to create a SageMaker Endpoint,\n",
    "    # SageMaker Model, and SageMaker Endpoint Config.\n",
    "    \"\"\"\n",
    "    sagemaker_client = boto3.client(service_name=\"sagemaker\", region_name=boto3.Session().region_name)\n",
    "    session_settings = sm.session_settings.SessionSettings(local_download_dir=local_download_dir)\n",
    "    session = sm.session.Session(sagemaker_client=sagemaker_client, settings=session_settings)\n",
    "    return session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b8329a7-2a99-4d05-bfed-3d0c16675765",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './download_dir'\n",
    "if not os.path.exists(model_path):\n",
    "    os.mkdir(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d99c2df-f852-4ecf-abca-b92117aafd33",
   "metadata": {},
   "source": [
    "### SageMaker Configuration Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e95d7296-12bd-4909-a3b1-4e0170925176",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "role               = sm.get_execution_role()\n",
    "sagemaker_session  = get_sagemaker_session(model_path) # sm.session.Session()\n",
    "region             = sagemaker_session._region_name\n",
    "\n",
    "# These are needed to show where the streamlit app is hosted\n",
    "sagemaker_metadata = json.load(open('/opt/ml/metadata/resource-metadata.json', 'r'))\n",
    "domain_id          = sagemaker_metadata['DomainId']\n",
    "resource_name      = sagemaker_metadata['ResourceName']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6675241-bdb3-4a20-ae4b-d1dd0ea091c7",
   "metadata": {},
   "source": [
    "### Boto Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48fef4a3-e6f5-485e-935f-4ee554b81bd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bucket     = 'sagemaker-studio-nh1d3ueatt'\n",
    "prefix     = 'textract'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92f62d4-e4da-44fc-9def-da5043bc4bce",
   "metadata": {},
   "source": [
    "# Model\n",
    "The following section will deploy the JumpStart model `flan-###`. There are additional steps required if launching 3rd-party proprietary models. These steps are detailed in another section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29a41d5-e6a4-4cbc-9002-cca7d5b3be70",
   "metadata": {},
   "source": [
    "### Select Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08931fa6-c696-44b5-9b25-1526a13d1c74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available text2text Models:\n",
      "--------------------------------\n",
      "huggingface-text2text-bart4csc-base-chinese\n",
      "huggingface-text2text-bigscience-t0pp\n",
      "huggingface-text2text-bigscience-t0pp-bnb-int8\n",
      "huggingface-text2text-bigscience-t0pp-fp16\n",
      "huggingface-text2text-flan-t5-base\n",
      "huggingface-text2text-flan-t5-base-samsum\n",
      "huggingface-text2text-flan-t5-large\n",
      "huggingface-text2text-flan-t5-small\n",
      "huggingface-text2text-flan-t5-xl\n",
      "huggingface-text2text-flan-t5-xxl\n",
      "huggingface-text2text-flan-t5-xxl-bnb-int8\n",
      "huggingface-text2text-flan-t5-xxl-fp16\n",
      "huggingface-text2text-flan-ul2-bf16\n",
      "huggingface-text2text-pegasus-paraphrase\n",
      "huggingface-text2text-qcpg-sentences\n",
      "huggingface-text2text-t5-one-line-summary\n"
     ]
    }
   ],
   "source": [
    "filter_value = \"task == text2text\"\n",
    "text_generation_models = list_jumpstart_models(filter=filter_value)\n",
    "print('Available text2text Models:\\n--------------------------------')\n",
    "_ = [print(m) for m in text_generation_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e071ec1d-1f79-4c90-9ba8-a8342557b48e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model that will be deployed is: huggingface-text2text-flan-t5-xxl\n"
     ]
    }
   ],
   "source": [
    "model_id = text_generation_models[7]\n",
    "model_version = '*'\n",
    "print(f'The model that will be deployed is: {model_id}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f61a31-18f5-4eb5-8454-3b532bb832b5",
   "metadata": {},
   "source": [
    "### Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fed9aa2-dd63-4879-9098-68c321935480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint: LLM-Context-in-a-box-huggingface-text2t-2023-05-11-18-48-58-636\n"
     ]
    }
   ],
   "source": [
    "endpoint_name = name_from_base(f\"LLM-Context-in-a-box-{model_id}\")\n",
    "print(f'Endpoint: {endpoint_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa80c3c5-5c8e-4447-a4b7-fd760d3470b3",
   "metadata": {},
   "source": [
    "#### Collect Model Containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e45bbd3c-7754-4b99-9dfc-4e1fd8b56d5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instance_type = \"ml.g5.2xlarge\"\n",
    "\n",
    "image_uri = image_uris.retrieve(\n",
    "    region=None,\n",
    "    framework=None,\n",
    "    image_scope=\"inference\",\n",
    "    model_id=model_id,\n",
    "    model_version=model_version,\n",
    "    instance_type=instance_type,\n",
    ")\n",
    "\n",
    "model_data = model_uris.retrieve(\n",
    "    model_id=model_id,\n",
    "    model_version=model_version,\n",
    "    model_scope=\"inference\"\n",
    ")\n",
    "\n",
    "print(f'The image URI is:  {image_uri}')\n",
    "print(f'The model data is: {model_data}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4165182-7a1f-4f4b-9473-31c1a8d5a31b",
   "metadata": {},
   "source": [
    "#### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a6b7503-05ae-4b4a-8a22-95d57d5d49a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Model(\n",
    "    image_uri=image_uri,\n",
    "    model_data=model_data,\n",
    "    role=role,\n",
    "    predictor_cls=Predictor,\n",
    "    name=endpoint_name,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    env={\"TS_DEFAULT_WORKERS_PER_MODEL\": \"1\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec096a3-f0a2-4c12-baec-988d33e48814",
   "metadata": {},
   "source": [
    "#### Deploy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25fb2465-c43b-497a-9d36-11c7f5c5d911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------!"
     ]
    }
   ],
   "source": [
    "model_predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    predictor_cls=Predictor,\n",
    "    endpoint_name=endpoint_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cd4eea-1194-44cf-b9ec-93d67b724ae8",
   "metadata": {},
   "source": [
    "#### Test that the model is correctly deployed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f82595ec-788c-455c-b884-28685a45b99b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Place your pizza dough on a flat baking pan. Top with sauce and cheese. Place your toppings on the pizza and cover your pizza with another layer of the pizza sauce and cheese. Top with mozzarella cheese and bake it in the oven.\n"
     ]
    }
   ],
   "source": [
    "sagemaker = boto3.client('sagemaker-runtime', region_name=region)\n",
    "input_question = 'Tell me the steps to make a pizza:'\n",
    "payload = {\n",
    "    \"text_inputs\": input_question,\n",
    "    \"max_length\": 50,\n",
    "    \"max_time\": 50,\n",
    "    \"num_return_sequences\": 1,\n",
    "    \"top_k\": 50,\n",
    "    \"top_p\": 0.95,\n",
    "    \"do_sample\": True,\n",
    "}\n",
    "\n",
    "\n",
    "response = sagemaker.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType=\"application/json\",\n",
    "    Body=json.dumps(payload).encode('utf-8')\n",
    ")\n",
    "output_answer = json.loads(response['Body'].read().decode('utf-8'))[\"generated_texts\"][0]\n",
    "print(output_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520b7d82-22d3-407c-b39a-cce6d6228627",
   "metadata": {},
   "source": [
    "## How to deploy 3rd-party Foundation Models\n",
    "1. Gain access to the foundation models\n",
    "    1. Go to the SageMaker Console\n",
    "    2. There will be a tab for JumpStart > Foundation Models\n",
    "    3. You must request access if you do not already have it\n",
    "2. Select the Foundation you would like to deploy\n",
    "3. Click `Subscribe` in the top-right corner\n",
    "4. After completing, this will allow you to open a notebook that lets you deploy the model\n",
    "5. Open the notebook\n",
    "6. You run this notebook to deploy the model, the caveat is that you must have access to any instance you choose to run.\n",
    "    1. For AI21 Summarization model, you can use something like: ml.g4dn.12xlarge\n",
    "    2. For AI21 Grande Instruct, you can use: ml.g5.24xlarge\n",
    "    3. For AI21 Jumbo Instruct, you can use: ml.g5.48xlarge\n",
    "    4. These were tested to work as of 2023-05-16\n",
    "    5. Collect these endpoint names and use them in the application_metadata JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd115f4-adea-4bb0-8b9d-27688f9fc0c6",
   "metadata": {},
   "source": [
    "# Streamlit UI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e3fe89-05e0-4d67-9623-36c759667570",
   "metadata": {},
   "source": [
    "### Record any parameters that need to be passed to the Streamlit app\n",
    "App Metadata Structure:\n",
    "#### application_metadata\n",
    " - models: a dictionary that contains the model display name, SageMaker endpoint name, and the model type (Currently 'sm' or 'ai21')\n",
    "   - name\n",
    "   - endpoint\n",
    "   - type\n",
    " - summary_model: the summary model endpoint name\n",
    " - region: the region (us-east-1 etc)\n",
    " - role: the permissions for the application. it should include (SageMaker, Textract, and Kendra access)\n",
    " - datastore: a dictionary that contains the bucket and folder prefix used to store document data\n",
    "   - bucket\n",
    "   - prefix\n",
    " - kendra: a dictionary that contains information on the Kendra index to be used when searching\n",
    "   - index_id\n",
    "   - index_name\n",
    "   - index_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30efe175-2817-4ff3-8023-a4fe0f50251b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "application_metadata = {\n",
    "    'models':[\n",
    "        {'name':'FLAN-Small', 'endpoint':'LLM-in-a-box-huggingface-text2text-flan-2023-05-18-19-23-11-479', 'type':'sm'},\n",
    "        {'name':'Super Fancy Model', 'endpoint':'', 'type':'ai21'}],\n",
    "    'summary_model':'sumsum',\n",
    "    'region':region,\n",
    "    'role':role,\n",
    "    'datastore':\n",
    "        {'bucket':bucket, 'prefix':prefix},\n",
    "}\n",
    "json.dump(application_metadata, open('application_metadata_doc.json', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1e0ed2-aa06-4c23-a90c-c4158deb925a",
   "metadata": {},
   "source": [
    "### Write the Streamlit app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32c9c3a4-b801-4a5a-8fbc-dbd500b78516",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app_doc.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app_doc.py\n",
    "import os\n",
    "import time\n",
    "import ai21\n",
    "import json\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import streamlit as st\n",
    "\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from collections import deque\n",
    "from datetime import datetime\n",
    "from pdf2image import convert_from_bytes\n",
    "st.set_page_config(layout=\"wide\")\n",
    "\n",
    "APP_MD    = json.load(open('application_metadata_doc.json', 'r'))\n",
    "MODELS    = {d['name']: d['endpoint'] for d in APP_MD['models']}\n",
    "MODEL_SUM = APP_MD['summary_model']\n",
    "REGION    = APP_MD['region']\n",
    "BUCKET    = APP_MD['datastore']['bucket']\n",
    "PREFIX    = APP_MD['datastore']['prefix']\n",
    "\n",
    "S3            = boto3.client('s3', region_name=REGION)\n",
    "TEXTRACT      = boto3.client('textract', region_name=REGION)\n",
    "SAGEMAKER     = boto3.client('sagemaker-runtime', region_name=REGION)\n",
    "CHAT_FILENAME = 'chat.csv'\n",
    "\n",
    "\n",
    "def query_endpoint(endpoint_name, payload):\n",
    "    if 'huggingface' in endpoint_name:\n",
    "        response = SAGEMAKER.invoke_endpoint(\n",
    "            EndpointName=endpoint_name,\n",
    "            ContentType='application/json',\n",
    "            Body=json.dumps(payload).encode('utf-8')\n",
    "        )\n",
    "        output_answer = json.loads(response['Body'].read().decode('utf-8'))[\"generated_texts\"][0]\n",
    "    else:\n",
    "        response = ai21.Completion.execute(\n",
    "            sm_endpoint=endpoint_name,\n",
    "            prompt=payload['text_inputs'],\n",
    "            maxTokens=payload['max_length'],\n",
    "            temperature=payload['temperature'],\n",
    "            stopSequences=['##'],\n",
    "            numResults=1\n",
    "        )\n",
    "        output_answer = response['completions'][0]['data']['text']\n",
    "    return str(output_answer)\n",
    "\n",
    "\n",
    "def extract_text(bucket, filepath):\n",
    "    response = TEXTRACT.start_document_text_detection(DocumentLocation={'S3Object': {'Bucket':bucket, 'Name':filepath}})\n",
    "    text = TEXTRACT.get_document_text_detection(JobId=response['JobId'])\n",
    "    i = 0\n",
    "    while text['JobStatus'] != 'SUCCEEDED':\n",
    "        time.sleep(5)\n",
    "        i += 1\n",
    "        text = TEXTRACT.get_document_text_detection(JobId=response['JobId'])\n",
    "        if i >= 10:\n",
    "            text = ''\n",
    "            break\n",
    "    text = '\\n'.join([t['Text'] for t in text['Blocks'] if t['BlockType']=='LINE'])\n",
    "    return text\n",
    "\n",
    "\n",
    "def load_document(file_bytes):\n",
    "    try:\n",
    "        images = convert_from_bytes(file_bytes)\n",
    "        image_page_1 = images[0].convert('RGB')\n",
    "        st.image(image_page_1)\n",
    "    except:\n",
    "        st.write('Cannot display image. Ensure that you have poppler-utils installed.')\n",
    "    \n",
    "    with open('doc.pdf', 'wb') as fp:\n",
    "        fp.write(file_bytes)\n",
    "    with open('doc.pdf', 'rb') as fp:\n",
    "        S3.upload_fileobj(fp, BUCKET, PREFIX+'/doc.pdf')\n",
    "    time.sleep(2)\n",
    "    text = extract_text(BUCKET, PREFIX+'/doc.pdf')\n",
    "    return text\n",
    "\n",
    "\n",
    "def summarize_context(context):\n",
    "    try:\n",
    "        response = ai21.Summarize.execute(\n",
    "            source=context,\n",
    "            sourceType=\"TEXT\",\n",
    "            sm_endpoint=MODEL_SUM\n",
    "        )\n",
    "        return response.summary\n",
    "    except:\n",
    "        return 'No summarization endpoint connected'\n",
    "\n",
    "\n",
    "def action_doc(params):\n",
    "    st.title('Ask Questions of your Document')\n",
    "    col1, col2 = st.columns(2)\n",
    "    with col1:\n",
    "        file = st.file_uploader('Upload a PDF file', type=['pdf'])\n",
    "        if file is not None:\n",
    "            context = load_document(file.read())\n",
    "    with col2:\n",
    "        if file is not None:\n",
    "            st.write('**Summary:**')\n",
    "            st.write(summarize_context(context))\n",
    "        input_question = st.text_input('**Please ask a question of a loaded document:**', '')\n",
    "        if st.button('Send Question') and len(input_question) > 3:\n",
    "            payload = {\n",
    "                \"text_inputs\": context + '##\\n' + input_question,\n",
    "                \"max_length\": params['max_len'],\n",
    "                \"max_time\": 50,\n",
    "                \"num_return_sequences\": 1,\n",
    "                \"top_k\": 50,\n",
    "                \"temperature\":params['temp'],\n",
    "                \"top_p\": params['top_p'],\n",
    "                \"do_sample\": True,\n",
    "            }\n",
    "            output_answer = query_endpoint(params['endpoint'], payload)\n",
    "            st.text_area('Response:', output_answer)\n",
    "\n",
    "\n",
    "def app_sidebar():\n",
    "    with st.sidebar:\n",
    "        st.write('## How to use:')\n",
    "        description = \"\"\"Welcome to our LLM tool extraction and query answering application. With this app, you can aske general question, \n",
    "        ask questions of a specific document, or intelligently search an internal document corpus. By selection the action you would like to perform,\n",
    "         you can ask general questions, or questions of your document. Additionally, you can select the model you use, to perform real-world tests to determine model strengths and weakneses.\"\"\"\n",
    "        st.write(description)\n",
    "        st.write('---')\n",
    "        st.write('### User Preference')\n",
    "        action_name = st.selectbox('Choose Activity', options=['Document Query'])\n",
    "        model_name = st.selectbox('Select Model', options=MODELS.keys())\n",
    "        max_len = st.slider('Max Length', min_value=50, max_value=500, value=150, step=10)\n",
    "        top_p = st.slider('Top p', min_value=0., max_value=1., value=1., step=.01)\n",
    "        temp = st.slider('Temperature', min_value=0.01, max_value=1., value=1., step=.01)\n",
    "        st.write('---')\n",
    "        st.write('## FAQ')\n",
    "        st.write(f'**1. Where is the model stored?** \\n\\nThe current model is: `{model_name}` and is running within your account.')\n",
    "        st.write(f'**2. Where is my data stored?**\\n\\nAny data you upload is stored into your S3 bucket: `{BUCKET}/{PREFIX}/`. Currently the queries you make to the endpoint are not stored, but you can enable this by capturing data from your endpoint.')\n",
    "        st.write('---')\n",
    "        params = {'action_name':action_name,'endpoint':MODELS[model_name], 'max_len':max_len, 'top_p':top_p, 'temp':temp, 'model_name':model_name}\n",
    "        return params\n",
    "\n",
    "\n",
    "def main():\n",
    "    params = app_sidebar()\n",
    "    endpoint=params['endpoint']\n",
    "    if params['action_name'] == 'Document Query':\n",
    "        action_doc(params)\n",
    "    else:\n",
    "        raise ValueError('Invalid action name.')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb95bae-89c1-4a82-9b9d-8b8231e46356",
   "metadata": {},
   "source": [
    "# Start App"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea64869-f6e1-4b5d-b054-001342ea5823",
   "metadata": {},
   "source": [
    "### Run Streamlit\n",
    "To run the application:\n",
    "1. Select File > New > Terminal\n",
    "2. In the terminal, use the command: `streamlit run app_doc.py --server.runOnSave true`\n",
    "   1. Note: ensure you have installed all required packages\n",
    "3. If this is successful, you will be able to interact with the app by using the web address below\n",
    "4. An important thing to note is that when you run the above command, you should see an output similar to below.\n",
    "5. The port thats  displayed is the same port that MUST be used after the `proxy` folder below.\n",
    "`\n",
    "You can now view your Streamlit app in your browser.\n",
    "\n",
    "  Network URL: http://###.###.###.###:8501\\\n",
    "  External URL: http://###.###.###.###:8501\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30689152-b9fa-4a23-9539-eb0613e32280",
   "metadata": {},
   "source": [
    "#### Display Link to Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58c9b5f3-5497-454f-b142-fee9afa2e36e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://d-qxdwe39zkab0.studio.us-east-1.sagemaker.aws/jupyter/default/proxy/8501/\n"
     ]
    }
   ],
   "source": [
    "print(f'http://{domain_id}.studio.{region}.sagemaker.aws/jupyter/default/proxy/8501/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dafa31-ab8b-4916-869a-a2744b5d9ef1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4611b03-ecbd-4a47-8e92-2406e04538f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7452b40d-b6c9-43a0-a963-c7f6e6504b20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
