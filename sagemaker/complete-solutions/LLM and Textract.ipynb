{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c2c2244-ef22-4904-9fd7-e8eb32d68a87",
   "metadata": {},
   "source": [
    "# Where to use this app\n",
    "1. Create a SageMaker Studio Domain if you don't have one\n",
    "2. Open SageMaker Studio under the user you plan to launch this applicatio\n",
    "3. Either upload this notebook, or clone the repository: [repo](https://github.com/chaeAclark/literate-eureka.git)\n",
    "4. Open the notebook `LLM in a box.ipynb`\n",
    "5. You can run the entire notebook by clicking Run > Run All Cells\n",
    "6. Alternatively, you can run the cells individually"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d488a4-dc68-4d1c-8efb-56e313cc86fb",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472f1b1b-cef6-49f8-9546-9d421f80a9ba",
   "metadata": {},
   "source": [
    "#### Update SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f041d93d-9f72-4b1a-9efb-1efabc37da23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U sagemaker --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc66d22-7dee-4ef7-ada9-b25900fa6f45",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cce0167c-5ac4-4ad9-a64b-e3c6c928b05c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import boto3\n",
    "import pickle\n",
    "import sagemaker as sm\n",
    "\n",
    "from sagemaker import image_uris\n",
    "from sagemaker import model_uris\n",
    "from sagemaker import script_uris\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.utils import name_from_base\n",
    "\n",
    "from sagemaker.jumpstart.notebook_utils import list_jumpstart_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22fbfba-019e-4c43-a2b5-c8629c830f7b",
   "metadata": {},
   "source": [
    "### Setup a Temporary Directory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "801fdd4f-f3c0-4605-8b50-f2ca09366e64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_sagemaker_session(local_download_dir) -> sm.Session:\n",
    "    sagemaker_client = boto3.client(service_name=\"sagemaker\", region_name=boto3.Session().region_name)\n",
    "    session_settings = sm.session_settings.SessionSettings(local_download_dir=local_download_dir)\n",
    "    session = sm.session.Session(sagemaker_client=sagemaker_client, settings=session_settings)\n",
    "    return session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b8329a7-2a99-4d05-bfed-3d0c16675765",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './download_dir'\n",
    "if not os.path.exists(model_path):\n",
    "    os.mkdir(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d99c2df-f852-4ecf-abca-b92117aafd33",
   "metadata": {},
   "source": [
    "### SageMaker Configuration Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e95d7296-12bd-4909-a3b1-4e0170925176",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "role               = sm.get_execution_role()\n",
    "sagemaker_session  = get_sagemaker_session(model_path) # sm.session.Session()\n",
    "region             = sagemaker_session._region_name\n",
    "sagemaker_metadata = json.load(open('/opt/ml/metadata/resource-metadata.json', 'r'))\n",
    "domain_id          = sagemaker_metadata['DomainId']\n",
    "resource_name      = sagemaker_metadata['ResourceName']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92f62d4-e4da-44fc-9def-da5043bc4bce",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29a41d5-e6a4-4cbc-9002-cca7d5b3be70",
   "metadata": {},
   "source": [
    "## Select Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08931fa6-c696-44b5-9b25-1526a13d1c74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available text2text Models:\n",
      "--------------------------------\n",
      "huggingface-text2text-bart4csc-base-chinese\n",
      "huggingface-text2text-bigscience-t0pp\n",
      "huggingface-text2text-bigscience-t0pp-bnb-int8\n",
      "huggingface-text2text-bigscience-t0pp-fp16\n",
      "huggingface-text2text-flan-t5-base\n",
      "huggingface-text2text-flan-t5-base-samsum\n",
      "huggingface-text2text-flan-t5-large\n",
      "huggingface-text2text-flan-t5-small\n",
      "huggingface-text2text-flan-t5-xl\n",
      "huggingface-text2text-flan-t5-xxl\n",
      "huggingface-text2text-flan-t5-xxl-bnb-int8\n",
      "huggingface-text2text-flan-t5-xxl-fp16\n",
      "huggingface-text2text-flan-ul2-bf16\n",
      "huggingface-text2text-pegasus-paraphrase\n",
      "huggingface-text2text-qcpg-sentences\n",
      "huggingface-text2text-t5-one-line-summary\n"
     ]
    }
   ],
   "source": [
    "filter_value = \"task == text2text\"\n",
    "text_generation_models = list_jumpstart_models(filter=filter_value)\n",
    "print('Available text2text Models:\\n--------------------------------')\n",
    "_ = [print(m) for m in text_generation_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e071ec1d-1f79-4c90-9ba8-a8342557b48e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model that will be deployed is: huggingface-text2text-flan-t5-xxl\n"
     ]
    }
   ],
   "source": [
    "model_id = text_generation_models[9]\n",
    "model_version = '*'\n",
    "#model_id = 'huggingface-textgeneration1-bloomz-7b1-fp16'\n",
    "print(f'The model that will be deployed is: {model_id}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f61a31-18f5-4eb5-8454-3b532bb832b5",
   "metadata": {},
   "source": [
    "## Deploy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fed9aa2-dd63-4879-9098-68c321935480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint: LLM-Context-in-a-box-huggingface-text2t-2023-05-11-18-48-58-636\n"
     ]
    }
   ],
   "source": [
    "endpoint_name = name_from_base(f\"LLM-Context-in-a-box-{model_id}\")\n",
    "print(f'Endpoint: {endpoint_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa80c3c5-5c8e-4447-a4b7-fd760d3470b3",
   "metadata": {},
   "source": [
    "### Collect the containers required to deploy the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e45bbd3c-7754-4b99-9dfc-4e1fd8b56d5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instance_type = \"ml.g5.12xlarge\"\n",
    "\n",
    "image_uri = image_uris.retrieve(\n",
    "    region=None,\n",
    "    framework=None,\n",
    "    image_scope=\"inference\",\n",
    "    model_id=model_id,\n",
    "    model_version=model_version,\n",
    "    instance_type=instance_type,\n",
    ")\n",
    "\n",
    "model_data = model_uris.retrieve(\n",
    "    model_id=model_id,\n",
    "    model_version=model_version,\n",
    "    model_scope=\"inference\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4165182-7a1f-4f4b-9473-31c1a8d5a31b",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a6b7503-05ae-4b4a-8a22-95d57d5d49a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Model(\n",
    "    image_uri=image_uri,\n",
    "    model_data=model_data,\n",
    "    role=role,\n",
    "    predictor_cls=Predictor,\n",
    "    name=endpoint_name,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    env={\"TS_DEFAULT_WORKERS_PER_MODEL\": \"1\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec096a3-f0a2-4c12-baec-988d33e48814",
   "metadata": {},
   "source": [
    "### Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25fb2465-c43b-497a-9d36-11c7f5c5d911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------!"
     ]
    }
   ],
   "source": [
    "# deploy the Model. Note that we need to pass Predictor class when we deploy model through Model class,\n",
    "# for being able to run inference through the sagemaker API.\n",
    "model_predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    predictor_cls=Predictor,\n",
    "    endpoint_name=endpoint_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cd4eea-1194-44cf-b9ec-93d67b724ae8",
   "metadata": {},
   "source": [
    "#### Test that the model is correctly deployed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f82595ec-788c-455c-b884-28685a45b99b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Place your pizza dough on a flat baking pan. Top with sauce and cheese. Place your toppings on the pizza and cover your pizza with another layer of the pizza sauce and cheese. Top with mozzarella cheese and bake it in the oven.\n"
     ]
    }
   ],
   "source": [
    "sagemaker = boto3.client('sagemaker-runtime', region_name=region)\n",
    "input_question = 'Tell me the steps to make a pizza:'\n",
    "payload = {\n",
    "    \"text_inputs\": input_question,\n",
    "    \"max_length\": 50,\n",
    "    \"max_time\": 50,\n",
    "    \"num_return_sequences\": 1,\n",
    "    \"top_k\": 50,\n",
    "    \"top_p\": 0.95,\n",
    "    \"do_sample\": True,\n",
    "}\n",
    "\n",
    "\n",
    "response = sagemaker.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType=\"application/json\",\n",
    "    Body=json.dumps(payload).encode('utf-8')\n",
    ")\n",
    "output_answer = json.loads(response['Body'].read().decode('utf-8'))[\"generated_texts\"][0]\n",
    "print(output_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e3fe89-05e0-4d67-9623-36c759667570",
   "metadata": {},
   "source": [
    "### Export any variables needed for the application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30efe175-2817-4ff3-8023-a4fe0f50251b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "application_metadata = {'endpoint_name':endpoint_name, 'region':region}\n",
    "json.dump(application_metadata, open('application_metadata.json', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1e0ed2-aa06-4c23-a90c-c4158deb925a",
   "metadata": {},
   "source": [
    "# Streamlit UI for PDF upload and summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32c9c3a4-b801-4a5a-8fbc-dbd500b78516",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app_textract.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app_textract.py\n",
    "import os\n",
    "import io\n",
    "import ai21\n",
    "import time\n",
    "import json\n",
    "import boto3\n",
    "import pickle\n",
    "import streamlit as st\n",
    "st.set_page_config(layout=\"wide\")\n",
    "\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from pdf2image import convert_from_bytes\n",
    "\n",
    "application_metadata = json.load(open('application_metadata.json', 'r'))\n",
    "endpoint_name = application_metadata['endpoint_name']\n",
    "s3_client = boto3.client('s3')\n",
    "textract_client = boto3.client('textract', region_name='us-east-1')\n",
    "sagemaker = boto3.client('sagemaker-runtime', region_name=application_metadata['region'])\n",
    "\n",
    "s3_bucket = 'sagemaker-studio-nh1d3ueatt'\n",
    "filepath = 'textract/doc.pdf'\n",
    "\n",
    "def display_image(pdf_bytes):\n",
    "    images = convert_from_bytes(pdf_bytes)\n",
    "    image_page_1 = images[0].convert('RGB')\n",
    "    st.image(image_page_1)\n",
    "\n",
    "\n",
    "def extract_text(s3_bucket, filepath):\n",
    "    response = textract_client.start_document_text_detection(DocumentLocation={'S3Object': {'Bucket':s3_bucket, 'Name':filepath}})\n",
    "    text = textract_client.get_document_text_detection(JobId=response['JobId'])\n",
    "    i = 0\n",
    "    while text['JobStatus'] != 'SUCCEEDED':\n",
    "        time.sleep(5)\n",
    "        i += 1\n",
    "        text = textract_client.get_document_text_detection(JobId=response['JobId'])\n",
    "        if i >= 10:\n",
    "            text = ''\n",
    "            break\n",
    "    text = '\\n'.join([t['Text'] for t in text['Blocks'] if t['BlockType']=='LINE'])\n",
    "    return text\n",
    "\n",
    "\n",
    "def summarize_text(text):\n",
    "    response = ai21.Summarize.execute(\n",
    "        source=text,\n",
    "        sourceType=\"TEXT\",\n",
    "        sm_endpoint='summarize'\n",
    "    )\n",
    "    st.write(response.summary)\n",
    "\n",
    "\n",
    "def main():\n",
    "    st.title('Ask Questions of your Document')\n",
    "    description = \"\"\"Welcome to our PDF extraction and query answering application. With this app, you can upload a PDF document that is processed using Amazon Textract. \n",
    "    After the text is extracted, you can use the attached LLM to ask specific \n",
    "    queries and get a response in natural language.\"\"\"\n",
    "    st.write(description)\n",
    "    text = ''\n",
    "    col1, col2 = st.columns(2)\n",
    "    \n",
    "    # The Sidebar holds information and frequently asked questions\n",
    "    with st.sidebar:\n",
    "        st.write('## How to use:')\n",
    "        st.write('First upload a PDF that you would like to analyze. After uploading, an image of the first page will be displayed and behind the scenes, Amazon Textract is used to extract any detected text. This context is passed to an LLM when making a specific query.')\n",
    "        st.write('---')\n",
    "        st.write('## Model Parameters:')\n",
    "        max_len = st.slider('Max Length', min_value=50, max_value=250, value=150, step=10)\n",
    "        top_p = st.slider('Top p', min_value=0., max_value=1., value=1., step=.01)\n",
    "        st.write('---')\n",
    "        st.write('## FAQ:')\n",
    "        st.write(f'**1. Where is the model stored?**\\n\\nThere are two models in use that are run on SageMaker endpoints within your account:\\n\\nSummarization: `summarize` and\\n\\nQnA: `{endpoint_name}`')\n",
    "        st.write(f'**2. Where is my data stored?**\\n\\nAny data you upload is stored into your S3 bucket: `{s3_bucket}`. Currently the queries you make to the endpoint are not stored, but you can enaable this by capturing data from your endpoint.')\n",
    "        st.write('---')\n",
    "    \n",
    "    # First column handles loading the PDF and displaying the first image\n",
    "    with col1:\n",
    "        file = st.file_uploader('Upload a PDF file', type=['pdf'])\n",
    "        if file is not None:\n",
    "            pdf_bytes = file.read()\n",
    "            with open('doc.pdf', 'wb') as fp:\n",
    "                fp.write(pdf_bytes)\n",
    "            with open('doc.pdf', 'rb') as fp:\n",
    "                s3_client.upload_fileobj(fp, s3_bucket, filepath)\n",
    "            display_image(pdf_bytes)\n",
    "            time.sleep(2)\n",
    "            text = text + extract_text(s3_bucket, filepath)\n",
    "    \n",
    "    # The second column allows users to query the document and communicates with teh SageMaker endpoint\n",
    "    with col2:\n",
    "        if file is not None:\n",
    "            st.write('**Summary:**')\n",
    "            st.write(summarize_text(text))\n",
    "        input_question = st.text_input('**Please ask a question of a loaded document:**', '')\n",
    "        if st.button('Send Question') and len(input_question) > 3:\n",
    "            payload = {\n",
    "                \"text_inputs\": text + '\\n' + input_question,\n",
    "                \"max_length\": max_len,\n",
    "                \"max_time\": 60,\n",
    "                \"num_return_sequences\": 1,\n",
    "                \"top_k\": 50,\n",
    "                \"top_p\": top_p,\n",
    "                \"do_sample\": True,\n",
    "            }\n",
    "            if True:\n",
    "                response = sagemaker.invoke_endpoint(\n",
    "                    EndpointName=endpoint_name,\n",
    "                    ContentType='application/json',\n",
    "                    Body=json.dumps(payload).encode('utf-8')\n",
    "                )\n",
    "                output_answer = json.loads(response['Body'].read().decode('utf-8'))[\"generated_texts\"][0]\n",
    "            else:\n",
    "                output_answer = 'I am not currently connected to an endpoint'\n",
    "            st.text_area('Response:', output_answer)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb95bae-89c1-4a82-9b9d-8b8231e46356",
   "metadata": {},
   "source": [
    "# Start App"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea64869-f6e1-4b5d-b054-001342ea5823",
   "metadata": {},
   "source": [
    "### Run Streamlit\n",
    "To run the application:\n",
    "1. Select File > New > Terminal\n",
    "2. In the terminal, use the command: `pip install streamlit boto3`\n",
    "3. In the terminal, use the command: `streamlit run app.py --server.runOnSave true`\n",
    "4. If this is successful, you will be able to interact with the app by using the web address below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30689152-b9fa-4a23-9539-eb0613e32280",
   "metadata": {},
   "source": [
    "#### Display Link to Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58c9b5f3-5497-454f-b142-fee9afa2e36e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://d-qxdwe39zkab0.studio.us-east-1.sagemaker.aws/jupyter/default/proxy/8501/\n"
     ]
    }
   ],
   "source": [
    "print(f'http://{domain_id}.studio.{region}.sagemaker.aws/jupyter/default/proxy/8501/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dafa31-ab8b-4916-869a-a2744b5d9ef1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4611b03-ecbd-4a47-8e92-2406e04538f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7452b40d-b6c9-43a0-a963-c7f6e6504b20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
