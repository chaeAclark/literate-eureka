{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0e17c69-52a0-4e18-9ecb-d153f255ae0b",
   "metadata": {},
   "source": [
    "# AI Research Assistant\n",
    "\n",
    "### Description\n",
    "\n",
    "This is a Python program that implements a Streamlit web application to serve as an AI research assistant. The aim is to help users discover and digest the latest academic papers in their field of interest through generated audio podcast episodes.\n",
    "\n",
    "The key problem this application aims to address is staying current on the immense volume of machine learning papers published, which can be inaccessible due to paywalls, dense technical material, and the time needed to read papers thoroughly. Many readers also prefer asynchronous audio content for learning.\n",
    "\n",
    "To accomplish this, the web app provides an interface for users to upload or specify PDF papers. It leverages AWS services to extract raw text from the PDFs using Textract OCR. This text is then passed to the Claude API hosted on Amazon Bedrock to generate a long-form summary, as well as metadata like title, authors, categories, and a sample code implementation. The summary text is formatted with SSML tags to optimize it for text-to-speech using Amazon Polly, which converts the text into an audio MP3.\n",
    "\n",
    "The benefits of this approach include leveraging large language models like Claude to quickly analyze and concisely summarize technical papers with little human input needed. Text-to-speech further adapts the content into an easy-to-consume audio format for passive listening. Showcasing sample code also makes ML concepts more tangible. Architecting the workflow serverlessly on AWS makes the app scalable and cost-effective.\n",
    "\n",
    "Overall, this AI research assistant web app aims to help users keep up with the latest ML advancements through auto-generated audio podcasts summarizing key papers in their field, lowering the barrier to benefitting from cutting edge research.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b370aba-dce9-43af-b455-20b4a0aa15e4",
   "metadata": {},
   "source": [
    "## Explanation of code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e08082a-c4ff-444a-a65b-bcd6b1388aa9",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "111e0a4d-d444-4c29-88ab-ea6bb7266a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "http://d-dedyt64u6kib.studio.us-east-1.sagemaker.aws/jupyter/default/proxy/8501/\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sagemaker as sm\n",
    "\n",
    "sagemaker_session  = sm.session.Session()\n",
    "region             = sagemaker_session._region_name\n",
    "\n",
    "# These are needed to show where the streamlit app is hosted\n",
    "sagemaker_metadata = json.load(open('/opt/ml/metadata/resource-metadata.json', 'r'))\n",
    "domain_id          = sagemaker_metadata['DomainId']\n",
    "resource_name      = sagemaker_metadata['ResourceName']\n",
    "\n",
    "print(f'http://{domain_id}.studio.{region}.sagemaker.aws/jupyter/default/proxy/8501/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22c81c1-2b28-4af6-ae54-e289ed340d8d",
   "metadata": {},
   "source": [
    "### Metadata\n",
    "This code block defines and creates the configuration parameters required for the streamlit application. This includes defining the models available as well as any additional resources. You should update this with the information you have access to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dbb5098-f6b1-4f44-a32f-e408d1b446bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_config = {\n",
    "    \"region\":\"us-east-1\",\n",
    "    \"datastores\":{\n",
    "        \"s3\":{\n",
    "            \"bucket\":\"chaeclrk-demo-genai-research-assistant\",\n",
    "            \"prefix\":\"data\",\n",
    "            \"pdfs\":\"pdfs\",\n",
    "            \"text\":\"text\",\n",
    "            \"audio\":\"audio\",\n",
    "            \"code\":\"code\",\n",
    "            \"transcripts\":\"transcripts\"\n",
    "        }\n",
    "    },\n",
    "    \"models_text\":[\n",
    "        {'name':'Anthropic Claude v2:1', 'endpoint':'anthropic.claude-v2:1'},\n",
    "        {'name':'Anthropic Claude v2', 'endpoint':'anthropic.claude-v2'},\n",
    "        {'name':'Anthropic Claude v1', 'endpoint':'anthropic.claude-v1'},\n",
    "    ],\n",
    "    \"models_image\":[],\n",
    "    \"models_embed\":[],\n",
    "    \"dynamo_table\":\"DemoResearchAssistantDocuments\",\n",
    "    \"arch_diagram\":\"research_assistant.png\",\n",
    "}\n",
    "json.dump(demo_config, open('config_demo_genai_research_assistant.json', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccf7aab-acb6-4d98-8d82-1af5bff9b566",
   "metadata": {},
   "source": [
    "### Streamlit UI\n",
    "This defines the streamlit code. See the main function for the code loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cf40a9e-a730-478c-be7f-d653c117ac20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting demo_genai_research_assistant.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile demo_genai_research_assistant.py\n",
    "import os\n",
    "import io\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import boto3\n",
    "import threading\n",
    "import numpy as np\n",
    "import streamlit as st\n",
    "\n",
    "from queue import Queue\n",
    "from icecream import ic\n",
    "from datetime import datetime\n",
    "from botocore.config import Config\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "st.set_page_config(layout=\"wide\", page_title=\"Research Assistant\")\n",
    "\n",
    "\n",
    "def initialize_session(filepath):\n",
    "    \"\"\"Initializes session state variables for chat history, context, and cost.\"\"\"\n",
    "    st.session_state['config'] = get_config(filepath)\n",
    "    st.session_state['papers'] = []\n",
    "    st.session_state['dynamodb_scan'] = []\n",
    "    st.session_state['papers_new'] = []\n",
    "    st.session_state['papers_old'] = []\n",
    "    st.session_state['papers_processed'] = []\n",
    "    st.session_state['papers_new_selected'] = []\n",
    "    st.session_state['papers_old_selected'] = []\n",
    "    return 0\n",
    "\n",
    "def get_about_me():\n",
    "    return \"\"\"This is a demo of an AI research assistant application built with Streamlit and deployed on AWS. The app allows users to upload or select PDF research papers, and will then use AWS services like Textract, Polly, and Bedrock to extract key information like the paper's title, authors, abstract summary, text transcript, and sample code implementations. The app shows how to build an end-to-end ML workflow from ingesting papers, running NLP models like Claude, and synthesizing audio podcast episodes using the generated summaries and code examples. Key features include extracting text from PDFs, querying large language models to analyze papers, converting text to speech with SSML tags, and storing output assets like text, audio, code in S3. The app aims to simplify discovering and summarizing the latest ML research in an engaging audio format.\"\"\"\n",
    "\n",
    "\n",
    "def get_arch_details():\n",
    "    return \"\"\"The application is built using Streamlit for the UI and AWS services for the ML workflow under the hood. The backend processing leverages AWS Textract to extract text from uploaded PDF papers. It then sends the extracted text as a prompt to Claude, a large language model API from Anthropic, to generate a paper summary, title, authors, and other metadata. The summary text is formatted with SSML tags optimized for text-to-speech using Amazon Polly, which converts the summary to an audio MP3. The application also generates sample code implementations using the Claude API. All the output text, audio, code assets are stored in an S3 bucket. Metadata about each paper is tracked in DynamoDB.\n",
    "\n",
    "The workflow parallelizes extracting the paper summary, metadata, and code example using Threads. Managing Streamlit caching and sessions state allows fast iterations on the frontend without re-running expensive backend jobs. The application architecture demonstrates an end-to-end machine learning pipeline on AWS leveraging services like S3, DynamoDB, Textract, Polly, and SageMaker in a serverless fashion. Additional features like user upload, audio playback, code rendering are enabled by Streamlit.\"\"\"\n",
    "\n",
    "\n",
    "def get_app_details():\n",
    "    return \"\"\"This AI Research Digest app enables users to upload academic papers, automatically generate rich summaries, and synthesize audio podcast episodes.\n",
    "\n",
    "For data ingestion, users can upload PDF papers from their local machine or specify an S3 bucket location. The application uses AWS Textract to extract the raw text from these PDFs. Both the original PDF and text are stored in designated S3 buckets for later retrieval.\n",
    "\n",
    "Once extracted, the full paper text is sent as a prompt to Claude, a large language model API from Anthropic accessed via Amazon Bedrock. The app runs 3 concurrent threads to generate the paper summary, metadata, and sample code implementation from the text. The summary is formatted using SSML tags to optimize the text for text-to-speech synthesis.\n",
    "\n",
    "Text-to-speech conversion leverages Amazon Polly. The marked up summary text is split into smaller paragraphs and sentences to avoid Polly service size limits. Synthesis requests are made in parallel using multiple threads. The resulting audio streams are concatenated to produce the final output audio file.\n",
    "\n",
    "All generated assets including the raw text, marked up transcript, audio file, and code snippet are stored in S3 buckets for persistence. Paper metadata like title, authors, and year are tracked in a DynamoDB table that acts as an index.\n",
    "\n",
    "The natural language prompts provided to Claude are designed to generate an appropriately formatted response. For example, the paper summary prompt explicitly asks for section headings like Introduction, Methods, and Results to improve structure. It also requests explanatory detail beyond the abstract to create an engaging audio narrative. The prompts are carefully tuned over multiple iterations to produce high quality output. As an illustration, the summary generation prompt is as follows:\n",
    "\n",
    "<prompt> Read the following research article and write a detailed summary of the paper's findings including background, data, models/algorithms, method/proposed solution, results, and any novel conclusions:\n",
    "Paper: <paper text>\n",
    "\n",
    "From the above paper, write a summary of the article's findings including background, data, models/algorithms, method/proposed solution, results, and any novel conclusions in <summary> tags. Be verbose and explain the concepts well. Define any uncommon terms... </prompt>\n",
    "\n",
    "By optimizing each step of the workflow - ingestion, summarization, synthesis, storage, and prompting - this app allows users to easily create AI-generated audio summaries from the latest academic papers.\"\"\"\n",
    "\n",
    "\n",
    "def get_config(filepath):\n",
    "    \"\"\"Loads configuration data from a JSON file including model endpoints, vector database indexes, AWS region, etc.\"\"\"\n",
    "    config = json.load(open(filepath, 'r'))\n",
    "    region = config['region']\n",
    "    diagram = config['arch_diagram']\n",
    "    \n",
    "    models_text = {d['name']: d['endpoint'] for d in config['models_text']}\n",
    "    #models_image = {d['name']: d['endpoint'] for d in md['models_image']}\n",
    "    #models_embed = {d['name']: d['endpoint'] for d in md['models_embed']}\n",
    "    \n",
    "    s3 = boto3.client(service_name='s3', region_name=region)\n",
    "    bucket = config['datastores']['s3']['bucket']\n",
    "    prefix = config['datastores']['s3']['prefix']\n",
    "    pdfs = config['datastores']['s3']['pdfs']\n",
    "    text = config['datastores']['s3']['text']\n",
    "    transcripts = config['datastores']['s3']['transcripts']\n",
    "    audio =  config['datastores']['s3']['audio']\n",
    "    code =  config['datastores']['s3']['code']\n",
    "    \n",
    "    polly = boto3.client(service_name='polly', region_name=region)\n",
    "    bedrock = boto3.client(service_name='bedrock-runtime', region_name=region, config=Config(read_timeout=240))\n",
    "    textract = boto3.client(service_name='textract', region_name=region)\n",
    "    dynamodb = boto3.resource(service_name='dynamodb', region_name=region).Table(config['dynamo_table'])\n",
    "    config = {\n",
    "        'models_text': models_text,\n",
    "        'region': region,\n",
    "        's3': s3,\n",
    "        'bucket': bucket,\n",
    "        'prefix': prefix,\n",
    "        'pdfs': pdfs,\n",
    "        'text': text,\n",
    "        'audio': audio,\n",
    "        'code': code,\n",
    "        'transcripts':transcripts,\n",
    "        'polly': polly,\n",
    "        'bedrock': bedrock,\n",
    "        'textract': textract,\n",
    "        'dynamodb': dynamodb,\n",
    "        'diagram': diagram,\n",
    "    }\n",
    "    return config\n",
    "\n",
    "\n",
    "def get_model_tags(endpoint):\n",
    "    \"\"\"Determines the formatting for user vs. AI prompts based on the model endpoint.\"\"\"\n",
    "    if 'claude' in endpoint:\n",
    "        human_tag = '\\n\\nHuman:'\n",
    "        robot_tag = '\\n\\nAssistant:'\n",
    "        split_tag = ''\n",
    "    else:\n",
    "        human_tag = '\\n\\n'\n",
    "        robot_tag = ''\n",
    "        split_tag = ''\n",
    "    return human_tag, robot_tag, split_tag\n",
    "\n",
    "\n",
    "def query_endpoint(client, endpoint, payload):\n",
    "    \"\"\"Calls the specified model endpoint on Amazon Bedrock with the given payload.\"\"\"\n",
    "    if 'claude' in endpoint:\n",
    "        body = json.dumps({\n",
    "            'prompt':payload['prompt'],\n",
    "            'max_tokens_to_sample':payload['max_len'],\n",
    "            'temperature':payload['temp'],\n",
    "            'top_p':payload['top_p'],\n",
    "        })\n",
    "        response, attempts, gen_time = call_bedrock(client, body, endpoint)\n",
    "        try:\n",
    "            response_body = json.loads(response.get(\"body\").read()).get(\"completion\")\n",
    "        except:\n",
    "            response_body = '**Failed to generate!**'\n",
    "    else:\n",
    "        raise ValueError(f'You have selected a model endpoint that is not supported ({endpoint}).\\nSupported endpoints: titan, claude, llama, cohere.')\n",
    "    return (response_body, attempts, gen_time)\n",
    "\n",
    "\n",
    "def call_bedrock(client, body, endpoint, attempts=12, accept='application/json', contentType='application/json'):\n",
    "    \"\"\"Makes requests to Bedrock with retries to invoke a model.\"\"\"\n",
    "    for i in range(attempts):\n",
    "        try:\n",
    "            tic = time.time()\n",
    "            response = client.invoke_model(\n",
    "                body=body,\n",
    "                modelId=endpoint,\n",
    "                accept=accept,\n",
    "                contentType=contentType\n",
    "            )\n",
    "            toc = time.time()\n",
    "            return response, i+1, toc-tic\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            time.sleep(5 + np.random.rand()/2.)\n",
    "            continue\n",
    "    return None, i+1, 0.\n",
    "\n",
    "\n",
    "@st.cache_data\n",
    "def upload_file_to_s3(file, bucket_name, object_name=None):\n",
    "    \"\"\"\n",
    "    Upload a file to an S3 bucket\n",
    "    from: https://stackoverflow.com/questions/63965781/how-to-upload-files-to-aws-s3-bucket-using-streamlit\n",
    "    \"\"\"\n",
    "    # If S3 object_name was not specified, use file name\n",
    "    if object_name is None:\n",
    "        object_name = file.name\n",
    "\n",
    "    # Upload the file\n",
    "    s3_client = boto3.client('s3')\n",
    "    try:\n",
    "        response = s3_client.upload_fileobj(file, bucket_name, object_name)\n",
    "    except ClientError as e:\n",
    "        st.error(f\"Could not upload file to S3: {e}\")\n",
    "        return False\n",
    "    st.success(f\"Uploaded {file.name} to {bucket_name}/{object_name}.\")\n",
    "    return True\n",
    "\n",
    "\n",
    "def load_mp3_from_s3(client, bucket, audio_path):\n",
    "    obj = client.get_object(Bucket=bucket, Key=audio_path)\n",
    "    audio_bytes = io.BytesIO(obj['Body'].read())\n",
    "    return audio_bytes\n",
    "\n",
    "\n",
    "def get_pdf_list(client, bucket, prefix):\n",
    "    response = client.list_objects_v2(Bucket=bucket, Prefix=prefix)\n",
    "    pdfs = [x['Key'] for x in response['Contents'] if x['Key'].endswith('.pdf')]\n",
    "    return pdfs\n",
    "\n",
    "def extract_text(data):\n",
    "    client = data['client']\n",
    "    bucket = data['bucket']\n",
    "    filepath = data['paper']\n",
    "    response = client.start_document_text_detection(\n",
    "        DocumentLocation={'S3Object': {'Bucket': bucket, 'Name': filepath}})\n",
    "    job_id = response['JobId']\n",
    "    \n",
    "    text = client.get_document_text_detection(JobId=response['JobId'])\n",
    "    i = 0\n",
    "    while text['JobStatus'] != 'SUCCEEDED':\n",
    "        time.sleep(1)\n",
    "        i += 1\n",
    "        text = client.get_document_text_detection(JobId=response['JobId'])\n",
    "        if i >= 120:\n",
    "            text = ''\n",
    "            break\n",
    "    \n",
    "    if type(text) is dict:\n",
    "        full_text = '\\n'.join([t['Text'] for t in text['Blocks'] if t['BlockType']=='LINE'])\n",
    "    else:\n",
    "        full_text = ''\n",
    "    while('NextToken' in text and text['NextToken'] != None):\n",
    "        text = client.get_document_text_detection(JobId=response['JobId'], NextToken=text['NextToken'])\n",
    "        if type(text) is dict:\n",
    "            full_text = full_text + '\\n'.join([t['Text'] for t in text['Blocks'] if t['BlockType']=='LINE'])\n",
    "        else:\n",
    "            full_text = full_text + ''\n",
    "    return full_text\n",
    "\n",
    "\n",
    "def polly_tag_examples():\n",
    "    tags = \"\"\"\n",
    "Amazon Polly supports the following SSML tags:\n",
    "1. Adding a Pause-<break>-Full availability\n",
    "2. Emphasizing Words-<emphasis>-Not available\n",
    "3. Specifying Another Language for Specific Words-<lang>-Full availability\n",
    "4. Placing a Custom Tag in Your Text-<mark>-Full availability\n",
    "5. Adding a Pause Between Paragraphs-<p>-Full availability\n",
    "6. Using Phonetic Pronunciation-<phoneme>-Full availability\n",
    "7. Controlling Volume, Speaking Rate, and Pitch-<prosody>-Partial availability\n",
    "8. Setting a Maximum Duration for Synthesized Speech-<prosody amazon:max-duration>-Not available\n",
    "9. Adding a Pause Between Sentences-<s>-Full availability\n",
    "10. Controlling How Special Types of Words Are Spoken-<say-as>-Partial availability\n",
    "11. Identifying SSML-Enhanced Text-<speak>-Full availability\n",
    "12. Pronouncing Acronyms and Abbreviations-<sub>-Full availability\n",
    "13. Improving Pronunciation by Specifying Parts of Speech-<w>-Full availability\n",
    "14. Adding the Sound of Breathing-<amazon:auto-breaths>-Not available\n",
    "15. Newscaster speaking style-<amazon:domain name=\"news\">-Select neural voices only\n",
    "16. Adding Dynamic Range Compression-<amazon:effect name=\"drc\">-Full availability\n",
    "17. Speaking Softly-<amazon:effect phonation=\"soft\">-Not available\n",
    "18. Controlling Timbre-<amazon:effect vocal-tract-length>-Not available\n",
    "19. Whispering-<amazon: effect name=\"whispered\">-Not available\n",
    "\"\"\"\n",
    "    return tags\n",
    "\n",
    "\n",
    "def get_polly_tags():\n",
    "    try:\n",
    "        with open('amazon_polly_tags.txt', 'r') as fp:\n",
    "            tags = fp.read()\n",
    "    except:\n",
    "        tags = polly_tag_examples()\n",
    "    return tags\n",
    "\n",
    "\n",
    "def get_paper_metadata(client, endpoint, payload, input_paper, q=None):\n",
    "    human_tag = payload['human_tag']\n",
    "    robot_tag = payload['robot_tag']\n",
    "    split_tag = payload['split_tag']\n",
    "    \n",
    "    prompt_template_pre = 'You are an AI Researcher whose goal is the analyze articles and extact requested content.'\n",
    "    prompt_template = \"\"\"Read the following article and extract:\n",
    "1. Title - the given or inferred title of the article\\n2. Year - the given or inferred year of the article\\n3. Authors - the authors of the article if present\\n4. Categories - write the list of categories that would help readers understand the content of the paper\n",
    "\\n<article>INPUT_PAPER</article>\\n\n",
    "From the above article extract the title, year, author, and category information and write the results as a JSON (e.g. {\"title\":\"...\", \"year\":\"...\", \"authors\":[\"...\", \"...\", ...], \"categories\":[\"...\", \"...\", ...]}).\"\"\"\n",
    "    prompt_template_post = 'Sure. Here is the extracted infomration with the correct title, year, authors, and categories as a valid JSON:\\n'\n",
    "    prompt_template_end = '{\"title\":\"'\n",
    "    prompt = human_tag + prompt_template_pre + prompt_template + robot_tag + prompt_template_post + prompt_template_end\n",
    "    prompt = prompt.replace('INPUT_PAPER', input_paper)\n",
    "    \n",
    "    payload['prompt'] = prompt\n",
    "    response = query_endpoint(client, endpoint, payload)\n",
    "    metadata = prompt_template_end + response[0].split('}')[0] + '}'\n",
    "    metadata = json.loads(metadata)\n",
    "    title            = metadata[\"title\"]\n",
    "    title_polly      = f'<p>The title of this paper is:</p> <p>{title}</p>'\n",
    "    year             = metadata[\"year\"]\n",
    "    year_polly       = f'<p>This paper was relased in {year}.</p>'\n",
    "    authors          = metadata[\"authors\"]\n",
    "    authors_polly    = f\"<p>There are {len(authors)} authors of this paper, with the lead author being {authors[0]}.</p>\"\n",
    "    categories       = metadata[\"categories\"]\n",
    "    categories_polly = \"<p>The most relevant categories for this paper are: </p><p>\" + '</p>,<p> '.join(categories[:-1]) + '</p>' + ', and <p>' + categories[-1] + '</p>'\n",
    "    if q is not None:\n",
    "        q.put(('title', title, title_polly))\n",
    "        q.put(('year', year, year_polly))\n",
    "        q.put(('authors', authors, authors_polly))\n",
    "        q.put(('categories', categories, categories_polly))\n",
    "    return title, title_polly, year, year_polly, authors, authors_polly, categories, categories_polly\n",
    "\n",
    "\n",
    "def get_summary_polly(client, endpoint, payload, input_summary):\n",
    "    human_tag = payload['human_tag']\n",
    "    robot_tag = payload['robot_tag']\n",
    "    split_tag = payload['split_tag']\n",
    "    \n",
    "    prompt_template_pre = ''\n",
    "    prompt_template = \"\"\"The following paper summary will be passed to Amazon Polly to be turned into speech for podcast audio.\n",
    "    Read and re-write the summary to be read by a speech to text service (e.g. \"This paper focuses on...\").\n",
    "    Use the relevant Amazon Polly tags:\\n\\nINPUT_POLLY:<polly-tags>\\n\\nSummary:<summary>INPUT_SUMMARY<summary>\n",
    "    \\nFrom the above text, adapt the summary to be read by Amazon Polly speech to text service in <summary_polly></summary_polly> tags.\n",
    "    For every section in the summary add any additional context that the listener needs to understand the goal and the results.\n",
    "    Use Speech Synthesis Markup Language (SSML) where relevant.\n",
    "    Be creative, this will be used to create a podcast, so also be verbose and specific.\n",
    "    Don't use non-supported tags like <emphasis>.\"\"\"\n",
    "    prompt_template_post = '''Sure! Happy to help. I will convert the paper summary above into valid Amazon Polly text following these guidelines:\n",
    "<guidelines>\n",
    "1. Simplify language and define terms\n",
    "- Avoid complex academic jargon and industry-specific terminology. Explain abbreviations/acronyms.\n",
    "- Define technical terms in simple language on first use. For example, \"Reinforcement learning (RL) is a type of machine learning that...\"\n",
    "2. Improve flow and structure\n",
    "- Use clear section headings (Introduction, Methods, Results, Discussion) and topic sentences.\n",
    "- Break up dense paragraphs into shorter 2-3 sentence chunks.\n",
    "- Use transitional phrases to guide the listener between ideas.\n",
    "3. Emphasize key points  \n",
    "- Identify 3-5 main takeaways and highlight using bold font or bullet point lists.\n",
    "- Rephrase main findings using strong declarative language and subject-verb sentence structure.\n",
    "4. Add explanatory detail  \n",
    "- Imagine you are explaining concepts to someone unfamiliar with the field. \n",
    "- Elaborate on the real-world significance of technical details. \n",
    "5. Use conversational language\n",
    "- Refer directly to the listener using \"we\", \"you\", \"us\" phrases.\n",
    "- Pose rhetorical questions to engage the listener.\n",
    "6. Check for common TTS errors\n",
    "- Read draft aloud, verify pronunciation of names/terms.\n",
    "- Check for misplaced pauses (incorrect commas).\n",
    "</guidelines>\\n\\n\n",
    "    '''\n",
    "    prompt_template_end = '<summary_polly><speak>'\n",
    "    prompt = human_tag + prompt_template_pre + prompt_template + robot_tag + prompt_template_post + prompt_template_end\n",
    "    prompt = prompt.replace('INPUT_POLLY', get_polly_tags())\n",
    "    prompt = prompt.replace('INPUT_SUMMARY', input_summary)\n",
    "    \n",
    "    payload['prompt'] = prompt\n",
    "    response = query_endpoint(client, endpoint, payload)\n",
    "    summary_polly = response[0].split('</speak></summary_polly>')[0]\n",
    "    return summary_polly\n",
    "\n",
    "\n",
    "def get_summary(client, endpoint, payload, input_paper, q=None):\n",
    "    human_tag = payload['human_tag']\n",
    "    robot_tag = payload['robot_tag']\n",
    "    split_tag = payload['split_tag']\n",
    "    \n",
    "    prompt_template_pre = ''\n",
    "    prompt_template = \"\"\"Read the following research article and write a detailed summary of the paper's findings including background, data,\n",
    "    models/algorithms, method/proposed solution, results, and any novel conclusions:\\n\\nPaper:<article>INPUT_PAPER</article>\\n\\n\n",
    "    From the above paper, write a summary of the articles findings including background, data, models/algorithms,\n",
    "    method/proposed solution, results, and any novel conclusions in <summary></summary> tags.\n",
    "    Be verbose and explain the concepts well. Define any uncommon terms.\n",
    "    This summary should go above and beyond the abstract including limitations as well as avenues for future exploration.\n",
    "    There should also be detailed examples and specifics where applicable.\"\"\"\n",
    "    prompt_template_post = ''\n",
    "    prompt_template_end = '<summary>'\n",
    "    prompt = human_tag + prompt_template_pre + prompt_template + robot_tag + prompt_template_end\n",
    "    prompt = prompt.replace('INPUT_PAPER', input_paper)\n",
    "    \n",
    "    payload['prompt'] = prompt\n",
    "    response = query_endpoint(client, endpoint, payload)\n",
    "    summary = response[0].split('</summary>')[0]\n",
    "    summary_polly = get_summary_polly(client, endpoint, payload, summary)\n",
    "    if q is not None:\n",
    "        q.put(('summary', summary, summary_polly))\n",
    "    return summary, summary_polly\n",
    "\n",
    "\n",
    "def get_code(client, endpoint, payload, input_paper, q=None):\n",
    "    human_tag = payload['human_tag']\n",
    "    robot_tag = payload['robot_tag']\n",
    "    split_tag = payload['split_tag']\n",
    "    \n",
    "    prompt_template_pre = 'You are an AI Researcher whose goal is to analyze articles and produce robust and understandable Python code examples.'\n",
    "    prompt_template = \"\"\"Read the following research paper and implement a well formatted and well documented code example,\n",
    "that impliments the models and/or algorithms precented in the paper. This can use sample data, but the explanation should be clear in the code:\n",
    "\\nPaper:<paper>INPUT_PAPER</paper>\\n\\nFrom the above paper, implement a well formatted and well documented code example in <code></code> tags,\n",
    "that impliments the models and/or algorithms precented in the paper. This can use sample data, but the explanation should be clear in the code.\n",
    "Before writing the code, list a detailed outline of what models/algorithms you plan to impliment and then what functions you would need to either impliment or use from a library.\"\"\"\n",
    "    prompt_template_post = 'Certainly. I will write well-documented and error free code. I will also detail all functions. My outline is:\\nOutline:\\n<outline>\\n'\n",
    "    prompt_template_end = '1. '\n",
    "    prompt = human_tag + prompt_template_pre + prompt_template + robot_tag + prompt_template_post + prompt_template_end\n",
    "    prompt = prompt.replace('INPUT_PAPER', input_paper)\n",
    "    \n",
    "    payload['prompt'] = prompt\n",
    "    response = query_endpoint(client, endpoint, payload)\n",
    "    try:\n",
    "        code = response[0].split('</code>')[0].split('<code>')[1]\n",
    "    except:\n",
    "        code = prompt_template_end + response[0]\n",
    "    code_polly = \"\"\n",
    "    if q is not None:\n",
    "        q.put(('code', code, code_polly))\n",
    "    return code, code_polly\n",
    "\n",
    "\n",
    "def fix_polly_text(data):\n",
    "    client = data['client']\n",
    "    endpoint = data['endpoint']\n",
    "    payload = data['payload']\n",
    "    input_text = data['text']\n",
    "    \n",
    "    human_tag = payload['human_tag']\n",
    "    robot_tag = payload['robot_tag']\n",
    "    split_tag = payload['split_tag']\n",
    "    \n",
    "    prompt_template_pre = ''\n",
    "    prompt_template = \"\"\"Read the following text prepared for Amazon Polly and correct any errors in the SSML tags used.\\n\\nPolly Text:INPUT_TEXT\\n\n",
    "    From the above Amazon Polly text, correct any errors in the text.\n",
    "    This includes ensuring all tags are opened and closed correctly, as well as only using supported tags (e.g. remove <emphasis> tags).\"\"\"\n",
    "    prompt_template_post = ''\n",
    "    prompt_template_end = '<speak>'\n",
    "    prompt = human_tag + prompt_template_pre + prompt_template + robot_tag + prompt_template_end\n",
    "    prompt = prompt.replace('INPUT_TEXT', input_text)\n",
    "    \n",
    "    payload['prompt'] = prompt\n",
    "    response = query_endpoint(client, endpoint, payload)\n",
    "    transcript_polly = prompt_template_end + response[0].split('</speak>')[0] + '</speak>'\n",
    "    return transcript_polly\n",
    "\n",
    "\n",
    "def split_polly_text(client, endpoint, payload, summary_polly, title_polly, authors_polly, categories_polly, year_polly, max_workers=20):\n",
    "    paper_polly = fix_polly_text({'client':client, 'endpoint':endpoint, 'payload':payload, 'text':summary_polly})\n",
    "    if '</p>' in paper_polly:\n",
    "        paper_polly_list = [t + '</p>' for t in paper_polly.replace('<speak>','').replace('</speak>','').split('</p>')[:-1]]\n",
    "    elif '</s>' in paper_polly:\n",
    "        paper_polly_list = [t + '</s>' for t in paper_polly.replace('<speak>','').replace('</speak>','').split('</s>')[:-1]]\n",
    "    else:\n",
    "        paper_polly_list = [t for t in paper_polly.replace('<speak>','').replace('</speak>','').replace('\\n\\n\\n','\\n').replace('\\n\\n','\\n').split('\\n')[:-1]]\n",
    "    \n",
    "    data_list = [{'client':client, 'endpoint':endpoint, 'payload':payload, 'text':text} for text in paper_polly_list]\n",
    "    with ThreadPoolExecutor(max_workers) as pool:\n",
    "        paper_polly_list = pool.map(fix_polly_text, data_list)\n",
    "    paper_polly_list = [p for p in paper_polly_list]\n",
    "    polly_start = '<speak>'\n",
    "    polly_end = '</speak>'\n",
    "    paper_polly_list = [polly_start+title_polly+polly_end, polly_start+year_polly+polly_end, polly_start+authors_polly+polly_end, polly_start+categories_polly+polly_end] + paper_polly_list\n",
    "    return paper_polly_list\n",
    "\n",
    "\n",
    "def call_polly(data):\n",
    "    def remove_xml_tags(text):\n",
    "        cleaned_text = \"\"  \n",
    "        xml_tag = re.compile(r\"<[^>]*>\")\n",
    "        fragments = xml_tag.split(text)\n",
    "        for fragment in fragments:\n",
    "            if not re.match(\"<[^>]*>\", fragment):\n",
    "                cleaned_text += fragment\n",
    "        return cleaned_text\n",
    "    \n",
    "    client = data['client']\n",
    "    text = data['text']\n",
    "    try:\n",
    "        response = client.synthesize_speech(Engine='neural', OutputFormat='mp3', Text=text, TextType='ssml', VoiceId='Joanna')\n",
    "    except:\n",
    "        try:\n",
    "            text = remove_xml_tags(text).replace('&','&amp;').replace(\"'\",\"&apos;\").replace('\"','&quot;').replace(\"<\",\"&lt;\").replace(\">\",\"&gt;\")\n",
    "            response = client.synthesize_speech(Engine='neural', OutputFormat='mp3', Text='<speak><p>'+text+'</p></speak>', TextType='ssml', VoiceId='Joanna')\n",
    "        except:\n",
    "            response = client.synthesize_speech(Engine='neural', OutputFormat='mp3', Text='<speak><p></p></speak>', TextType='ssml', VoiceId='Joanna')\n",
    "    return response\n",
    "\n",
    "\n",
    "def text_to_speech(client, text_list, max_workers=20):\n",
    "    data_list = [{'client':client, 'text':text} for text in text_list]\n",
    "    with ThreadPoolExecutor(max_workers) as pool:\n",
    "        responses = pool.map(call_polly, data_list)\n",
    "    \n",
    "    audio_stream = None\n",
    "    for audio in responses:\n",
    "        if audio_stream is None:\n",
    "            audio_stream = audio['AudioStream'].read()\n",
    "        else:\n",
    "            audio_stream += audio['AudioStream'].read()\n",
    "    return audio_stream\n",
    "\n",
    "\n",
    "def store_files(client, bucket, folder, filename, data, mode):\n",
    "    if mode == 'audio':\n",
    "        ext = '.mp3'\n",
    "    elif mode == 'code':\n",
    "        ext = '.py'\n",
    "    elif mode == 'paper' or mode == 'transcripts':\n",
    "        ext = '.txt'\n",
    "    else:\n",
    "        raise ValueError('Unknown mode')\n",
    "    key = folder + '/' + filename.split('.pdf')[0] + ext\n",
    "    client.put_object(Bucket=bucket, Key=key, Body=data)\n",
    "    return 's3://' + bucket + '/' + key\n",
    "\n",
    "\n",
    "def get_dynamodb_scan_full(table):\n",
    "    return table.scan()['Items']\n",
    "\n",
    "\n",
    "def get_dynamodb_scan(table):\n",
    "    response = get_dynamodb_scan_full(table)\n",
    "    paper_names = [item['PaperName'] for item in response]\n",
    "    return paper_names\n",
    "\n",
    "\n",
    "def get_item(table, paper_name, processed_timestamp=None):\n",
    "    if processed_timestamp is None:\n",
    "        response = table.get_item(\n",
    "            Key={'PaperName': paper_name},\n",
    "            KeyConditionExpression='PaperName = :name',\n",
    "            ExpressionAttributeValues={':name': paper_name}\n",
    "        )\n",
    "    else:\n",
    "        response = table.get_item(Key={'PaperName': paper_name, 'ProcessTimestamp': processed_timestamp})\n",
    "    return 'Item' in response\n",
    "\n",
    "\n",
    "def put_item(table, item):\n",
    "    # TODO: Impliment and error handling or correction checks\n",
    "    table.put_item(Item=item)\n",
    "    return\n",
    "\n",
    "\n",
    "def process_paper(config, endpoint, payload, paper_text, paper_path):\n",
    "    tic = time.time()\n",
    "    filename = os.path.basename(paper_path)\n",
    "    q = Queue()\n",
    "    t1 = threading.Thread(target=get_paper_metadata, args=(config['bedrock'], endpoint, payload, paper_text, q))\n",
    "    t2 = threading.Thread(target=get_summary, args=(config['bedrock'], endpoint, payload, paper_text, q))\n",
    "    t3 = threading.Thread(target=get_code, args=(config['bedrock'], endpoint, payload, paper_text, q))\n",
    "    t1.start(); t2.start(); t3.start()\n",
    "    t1.join(); t2.join(); t3.join()\n",
    "    toc = time.time() - tic\n",
    "    print(toc)\n",
    "    \n",
    "    title,title_polly,authors,authors_polly,categories,categories_polly,year,year_polly = '','','','','','','',''\n",
    "    for _ in range(q.qsize()):\n",
    "        tup = q.get()\n",
    "        if tup[0] == 'title':\n",
    "            title, title_polly = tup[1], tup[2]\n",
    "        elif tup[0] == 'authors':\n",
    "            authors, authors_polly = tup[1], tup[2]\n",
    "        elif tup[0] == 'categories':\n",
    "            categories, categories_polly = tup[1], tup[2]\n",
    "        elif tup[0] == 'year':\n",
    "            year, year_polly = tup[1], tup[2]\n",
    "        elif tup[0] == 'summary':\n",
    "            summary, summary_polly = tup[1], tup[2]\n",
    "        elif tup[0] == 'code':\n",
    "            code, code_polly = tup[1], tup[2]\n",
    "    \n",
    "    tic = time.time()\n",
    "    paper_polly_list = split_polly_text(config['bedrock'], endpoint, payload, summary_polly, title_polly, authors_polly, categories_polly, year_polly)\n",
    "    try:\n",
    "        paper_polly_stream = text_to_speech(config['polly'], paper_polly_list)\n",
    "    except Exception as e:\n",
    "        _ = [print(t) for t in paper_polly_list]\n",
    "        paper_polly_stream = text_to_speech(config['polly'], [\"<speak><p>Unfortunately, I was unable to convert the transcript into speech.</p><p> Please look at the output transcript to determine any issues.</p></speak>\"])\n",
    "    toc = time.time() - tic\n",
    "    print(toc)\n",
    "    \n",
    "    s3_paper_text = store_files(config['s3'], config['bucket'], config['prefix']+'/'+config['text'], filename, paper_text, mode='paper')\n",
    "    s3_paper_transcript = store_files(config['s3'], config['bucket'], config['prefix']+'/'+config['transcripts'], filename, summary_polly, mode='transcripts')\n",
    "    s3_paper_audio = store_files(config['s3'], config['bucket'], config['prefix']+'/'+config['audio'], filename, paper_polly_stream, mode='audio')\n",
    "    s3_paper_code = store_files(config['s3'], config['bucket'], config['prefix']+'/'+config['code'], filename, code, mode='code')\n",
    "    item = {\n",
    "        'PaperName':filename,\n",
    "        'ProcessTimestamp':str(datetime.now().strftime(\"%Y\")),\n",
    "        'PaperLocation':'s3://'+config['bucket']+'/'+paper_path,\n",
    "        'FullTextLocation':s3_paper_text,\n",
    "        'TranscriptLocation':s3_paper_transcript,\n",
    "        'CodeLocation':s3_paper_code,\n",
    "        'AudioLocation':s3_paper_audio,\n",
    "        'FoundationModel':endpoint,\n",
    "        'Title':title,\n",
    "        'Authors':authors,\n",
    "        'Year':year,\n",
    "        'Categories':categories,\n",
    "        'Summary':summary,\n",
    "        'Code':code,\n",
    "        'KeyReferences':'Not suported currently.',\n",
    "        'ResearchIdeas':'Not suported currently.',\n",
    "    }\n",
    "    put_item(config['dynamodb'], item)\n",
    "    return item, paper_polly_stream\n",
    "\n",
    "\n",
    "def sidebar(config):\n",
    "    st.sidebar.header('About the App')\n",
    "    st.sidebar.write(get_about_me())\n",
    "    st.sidebar.header('User Parameters')\n",
    "    with st.sidebar.expander('**Data Input/Output**'):\n",
    "        config['bucket'] = st.text_input('Bucket name', config['bucket'], disabled=False)\n",
    "        config['prefix'] = st.text_input('Data Folder', config['prefix'], disabled=False)\n",
    "        config['pdfs'] = st.text_input('Input PDF Location', config['pdfs'], disabled=False)\n",
    "        config['text'] = st.text_input('Output Text Location', config['text'], disabled=False)\n",
    "        config['audio'] = st.text_input('Output Audio Location', config['audio'], disabled=False)\n",
    "        config['code'] = st.text_input('Output Code Location', config['code'], disabled=False)\n",
    "        config['transcripts'] = st.text_input('Output Transcripts Location', config['transcripts'], disabled=False)\n",
    "    with st.sidebar.expander('**Model Parameters**'):\n",
    "        model_text = st.selectbox('Model', config['models_text'].keys())\n",
    "        max_len_text = st.number_input('Max Generation Length', 1000, 5000, 2500, 500) \n",
    "        temp_text = st.slider('Temperature', 0.01, 1., 0.01, .01)\n",
    "    with st.sidebar.expander('**File Upload**'):\n",
    "        local_file = st.file_uploader('You can upload a local PDF here', type=['pdf'])\n",
    "        if local_file is not None:\n",
    "            upload_file_to_s3(\n",
    "                local_file,\n",
    "                config['bucket'],\n",
    "                object_name=\"/\".join([config['prefix'], config['pdfs'], local_file.name])\n",
    "            )\n",
    "    config['model_text'] = model_text\n",
    "    config['max_len_text'] = max_len_text\n",
    "    config['temp_text'] = temp_text\n",
    "    config['model_text_endpoint'] = config['models_text'][model_text]\n",
    "    return config\n",
    "\n",
    "\n",
    "@st.cache_resource\n",
    "def apply_papers(papers_new, papers_old):\n",
    "    st.session_state['papers_new_selected'] = [p for p in st.session_state['papers'] if os.path.basename(p) in papers_new]\n",
    "    st.session_state['papers_old_selected'] = [p for p in st.session_state['papers'] if os.path.basename(p) in papers_old]\n",
    "\n",
    "\n",
    "def main(config, max_workers=20):\n",
    "    st.title(\"AI Research Digest - Discover the latest papers\")\n",
    "    st.subheader('Your daily AI research podcast')\n",
    "    with st.expander('How It Works'):\n",
    "        tab1, tab2 = st.tabs(['**Architecture**', '**App Details**'])\n",
    "        with tab1:\n",
    "            st.image(config['diagram'])\n",
    "            st.write(get_arch_details())\n",
    "        with tab2:\n",
    "            st.write(get_app_details())\n",
    "    \n",
    "    endpoint = config['model_text_endpoint']\n",
    "    payload = {\n",
    "        'prompt':'',\n",
    "        'max_len':config['max_len_text'],\n",
    "        'temp':config['temp_text'],\n",
    "        'top_p':.9\n",
    "    }\n",
    "    human_tag, robot_tag, split_tag = get_model_tags(endpoint)\n",
    "    payload['human_tag'] = human_tag\n",
    "    payload['robot_tag'] = robot_tag\n",
    "    payload['split_tag'] = split_tag\n",
    "    \n",
    "    col1, col2 = st.columns(2)\n",
    "    with col1:\n",
    "        st.subheader(\"Today's Top Papers\")\n",
    "        with st.expander('**Selected Papers**'):\n",
    "            btn1, btn2 = st.columns(2)\n",
    "            with btn1:\n",
    "                if st.button('Load Available Papers'):\n",
    "                    st.session_state['papers'] = sorted(get_pdf_list(config['s3'], config['bucket'], config['prefix'] + '/' + config['pdfs']))\n",
    "                    st.session_state['dynamodb_scan'] = get_dynamodb_scan(config['dynamodb'])\n",
    "                    st.session_state['papers_new'] = [os.path.basename(p) for p in st.session_state['papers'] if os.path.basename(p) not in st.session_state['dynamodb_scan']]\n",
    "                    st.session_state['papers_old'] = [os.path.basename(p) for p in st.session_state['papers'] if os.path.basename(p) in st.session_state['dynamodb_scan']]\n",
    "            \n",
    "            # Set the selected papers\n",
    "            papers_selected_new = st.multiselect('Select from unprocessed papers', st.session_state['papers_new'])\n",
    "            papers_selected_old = st.multiselect('Select from processed papers', st.session_state['papers_old'])\n",
    "            \n",
    "            with btn2:\n",
    "                if st.button('Summarize Papers'):\n",
    "                    apply_papers(papers_selected_new, papers_selected_old)\n",
    "                    \n",
    "                    # Process Old Papers\n",
    "                    paper_names = [os.path.basename(p) for p in st.session_state['papers_old_selected']]\n",
    "                    paper_items = [i for i in get_dynamodb_scan_full(config['dynamodb']) if i['PaperName'] in paper_names]\n",
    "                    for item in paper_items:\n",
    "                        audio = load_mp3_from_s3(config['s3'], item['AudioLocation'].split('/')[2],  \"/\".join(item['AudioLocation'].split('/')[3:]))\n",
    "                        st.session_state['papers_processed'].append({'title':item['Title'], 'audio':audio, 'summary':item['Summary'], 'code':item['Code']})\n",
    "                    \n",
    "                    # Process New Papers\n",
    "                    paper_data = [{'client':config['textract'], 'bucket':config['bucket'], 'paper':paper} for paper in st.session_state['papers_new_selected']]\n",
    "                    with ThreadPoolExecutor(max_workers) as pool:\n",
    "                        paper_list = pool.map(extract_text, paper_data)\n",
    "                    for paper, text in zip(st.session_state['papers_new_selected'], paper_list):\n",
    "                        item, audio = process_paper(config, endpoint, payload, text, os.path.basename(paper))\n",
    "                        st.session_state['papers_processed'].append({'title':item['Title'], 'audio':audio, 'summary':item['Summary'], 'code':item['Code']})\n",
    "                        time.sleep(5)\n",
    "    \n",
    "    \n",
    "    with col2:\n",
    "        st.subheader('Paper Breakdown')\n",
    "        for paper in st.session_state['papers_processed']:\n",
    "            with st.expander(f'**{paper[\"title\"]}**'):\n",
    "                st.write('Here is the audio session:')\n",
    "                st.audio(paper['audio'])\n",
    "                tab1, tab2 = st.tabs(['**Paper Summary**', '**Code Example**'])\n",
    "                with tab1:\n",
    "                    st.write(paper['summary'])\n",
    "                with tab2:\n",
    "                    st.code(paper['code'])\n",
    "    return\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    FILEPATH = './config_demo_genai_research_assistant.json'\n",
    "    if 'config' not in st.session_state:\n",
    "        initialize_session(FILEPATH)\n",
    "    config = sidebar(st.session_state['config'])\n",
    "    main(config)"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
